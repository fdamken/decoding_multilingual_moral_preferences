INFO - tinypaper - Running command 'main'
INFO - tinypaper - Started run with ID "184"
/Users/karina/Documents/Coding/PyCharm/mme/src/model/model.py:19: UserWarning: Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  warnings.warn(
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:29<24:11, 29.62s/it]  4%|▍         | 2/50 [00:55<22:06, 27.64s/it]  6%|▌         | 3/50 [01:25<22:32, 28.77s/it]  8%|▊         | 4/50 [01:57<22:59, 29.99s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.863(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 10%|█         | 5/50 [02:28<22:32, 30.06s/it] 12%|█▏        | 6/50 [02:57<21:49, 29.77s/it] 14%|█▍        | 7/50 [03:27<21:21, 29.81s/it] 16%|█▌        | 8/50 [03:55<20:29, 29.28s/it] 18%|█▊        | 9/50 [04:23<19:49, 29.01s/it] 20%|██        | 10/50 [04:54<19:45, 29.65s/it] 22%|██▏       | 11/50 [05:24<19:17, 29.67s/it] 24%|██▍       | 12/50 [05:52<18:25, 29.10s/it] 26%|██▌       | 13/50 [06:22<18:12, 29.54s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.429(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 3.039(s), this was the 2nd time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 28%|██▊       | 14/50 [06:54<18:09, 30.27s/it] 30%|███       | 15/50 [07:24<17:32, 30.07s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.720(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 32%|███▏      | 16/50 [07:55<17:16, 30.50s/it] 34%|███▍      | 17/50 [08:24<16:30, 30.03s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.202(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 36%|███▌      | 18/50 [08:52<15:34, 29.20s/it] 38%|███▊      | 19/50 [09:21<15:05, 29.20s/it] 40%|████      | 20/50 [09:49<14:26, 28.89s/it] 42%|████▏     | 21/50 [10:19<14:08, 29.25s/it] 44%|████▍     | 22/50 [10:45<13:12, 28.29s/it] 46%|████▌     | 23/50 [11:16<13:01, 28.94s/it] 48%|████▊     | 24/50 [11:45<12:34, 29.03s/it] 50%|█████     | 25/50 [12:14<12:03, 28.94s/it] 52%|█████▏    | 26/50 [12:41<11:25, 28.54s/it] 54%|█████▍    | 27/50 [13:10<10:57, 28.59s/it] 56%|█████▌    | 28/50 [13:36<10:13, 27.91s/it] 58%|█████▊    | 29/50 [14:03<09:41, 27.68s/it] 60%|██████    | 30/50 [14:32<09:21, 28.09s/it] 62%|██████▏   | 31/50 [15:01<08:57, 28.30s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.727(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 64%|██████▍   | 32/50 [15:34<08:56, 29.80s/it] 66%|██████▌   | 33/50 [16:05<08:31, 30.07s/it] 68%|██████▊   | 34/50 [16:34<07:56, 29.81s/it] 70%|███████   | 35/50 [17:04<07:27, 29.80s/it] 72%|███████▏  | 36/50 [17:36<07:05, 30.38s/it] 74%|███████▍  | 37/50 [18:08<06:42, 30.95s/it] 76%|███████▌  | 38/50 [18:37<06:03, 30.27s/it] 78%|███████▊  | 39/50 [19:07<05:32, 30.22s/it] 80%|████████  | 40/50 [19:36<04:57, 29.75s/it] 82%|████████▏ | 41/50 [20:07<04:32, 30.26s/it] 84%|████████▍ | 42/50 [20:37<04:02, 30.28s/it] 86%|████████▌ | 43/50 [21:05<03:26, 29.53s/it] 88%|████████▊ | 44/50 [21:33<02:54, 29.16s/it] 90%|█████████ | 45/50 [22:02<02:24, 28.91s/it] 92%|█████████▏| 46/50 [22:29<01:53, 28.38s/it] 94%|█████████▍| 47/50 [22:58<01:25, 28.63s/it] 96%|█████████▌| 48/50 [23:26<00:56, 28.34s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.935(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 98%|█████████▊| 49/50 [23:55<00:28, 28.67s/it]100%|██████████| 50/50 [24:23<00:00, 28.40s/it]100%|██████████| 50/50 [24:23<00:00, 29.27s/it]
INFO - tinypaper - Result: {'answers': [[2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2], [2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2], [2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2], [1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1], [2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2], [1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2], [2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1], [2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1], [2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1], [2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2], [2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2], [1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2], [2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2], [2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1], [1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1], [2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1], [2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2], [1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2], [1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1], [2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2], [2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2], [2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1], [2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2], [2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1], [2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1], [2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1], [2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1], [1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1], [1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1], [2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2], [1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2], [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2], [2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1], [2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2], [2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1], [2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1], [2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1], [2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1], [2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2], [2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1], [1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2], [2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1], [2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1], [1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1], [2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2], [2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1], [1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2], [2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2], [2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1]], 'api_usage': [APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0)], 'api_usage_total': APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-50, num_output_tokens=-50, cost=0.0)}
INFO - tinypaper - Completed after 0:24:24
