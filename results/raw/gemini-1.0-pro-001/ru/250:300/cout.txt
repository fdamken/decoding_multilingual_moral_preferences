INFO - tinypaper - Running command 'main'
INFO - tinypaper - Started run with ID "186"
/Users/karina/Documents/Coding/PyCharm/mme/src/model/model.py:19: UserWarning: Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  warnings.warn(
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:27<22:42, 27.81s/it]  4%|▍         | 2/50 [00:53<21:28, 26.85s/it]  6%|▌         | 3/50 [01:25<22:40, 28.95s/it]  8%|▊         | 4/50 [01:54<22:06, 28.84s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.017(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 10%|█         | 5/50 [02:25<22:22, 29.84s/it] 12%|█▏        | 6/50 [02:53<21:27, 29.25s/it] 14%|█▍        | 7/50 [03:21<20:36, 28.76s/it] 16%|█▌        | 8/50 [03:48<19:48, 28.31s/it] 18%|█▊        | 9/50 [04:19<19:52, 29.10s/it] 20%|██        | 10/50 [04:47<19:05, 28.65s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.422(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 2.546(s), this was the 2nd time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 22%|██▏       | 11/50 [05:17<18:58, 29.19s/it] 24%|██▍       | 12/50 [05:46<18:28, 29.17s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.226(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 26%|██▌       | 13/50 [06:14<17:38, 28.60s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.438(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 28%|██▊       | 14/50 [06:44<17:26, 29.06s/it] 30%|███       | 15/50 [07:11<16:35, 28.45s/it] 32%|███▏      | 16/50 [07:39<16:08, 28.48s/it] 34%|███▍      | 17/50 [08:08<15:40, 28.51s/it] 36%|███▌      | 18/50 [08:37<15:17, 28.68s/it] 38%|███▊      | 19/50 [09:06<14:53, 28.82s/it] 40%|████      | 20/50 [09:36<14:33, 29.13s/it] 42%|████▏     | 21/50 [10:06<14:10, 29.33s/it] 44%|████▍     | 22/50 [10:42<14:37, 31.33s/it] 46%|████▌     | 23/50 [11:13<14:06, 31.34s/it] 48%|████▊     | 24/50 [11:41<13:08, 30.33s/it] 50%|█████     | 25/50 [12:10<12:25, 29.83s/it] 52%|█████▏    | 26/50 [12:38<11:44, 29.36s/it] 54%|█████▍    | 27/50 [13:10<11:32, 30.11s/it] 56%|█████▌    | 28/50 [13:40<11:01, 30.08s/it] 58%|█████▊    | 29/50 [14:13<10:50, 30.98s/it] 60%|██████    | 30/50 [14:43<10:14, 30.73s/it] 62%|██████▏   | 31/50 [15:18<10:05, 31.88s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.546(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 64%|██████▍   | 32/50 [15:51<09:41, 32.30s/it] 66%|██████▌   | 33/50 [16:22<09:02, 31.89s/it] 68%|██████▊   | 34/50 [16:53<08:24, 31.54s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.532(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 70%|███████   | 35/50 [17:25<07:55, 31.69s/it] 72%|███████▏  | 36/50 [17:54<07:12, 30.89s/it] 74%|███████▍  | 37/50 [18:24<06:40, 30.80s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.721(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 76%|███████▌  | 38/50 [18:53<06:02, 30.22s/it] 78%|███████▊  | 39/50 [19:22<05:28, 29.91s/it] 80%|████████  | 40/50 [19:53<05:02, 30.21s/it] 82%|████████▏ | 41/50 [20:20<04:23, 29.26s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.556(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 84%|████████▍ | 42/50 [20:50<03:53, 29.22s/it] 86%|████████▌ | 43/50 [21:18<03:23, 29.08s/it] 88%|████████▊ | 44/50 [21:45<02:50, 28.33s/it] 90%|█████████ | 45/50 [22:18<02:28, 29.76s/it] 92%|█████████▏| 46/50 [22:46<01:56, 29.15s/it] 94%|█████████▍| 47/50 [23:15<01:27, 29.10s/it] 96%|█████████▌| 48/50 [23:42<00:57, 28.70s/it] 98%|█████████▊| 49/50 [24:12<00:29, 29.09s/it]100%|██████████| 50/50 [24:43<00:00, 29.39s/it]100%|██████████| 50/50 [24:43<00:00, 29.66s/it]
INFO - tinypaper - Result: {'answers': [[2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1], [2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2], [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2], [2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1], [1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2], [2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1], [1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2], [2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1], [2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1], [1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2], [1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1], [2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1], [1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1], [2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2], [2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1], [1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1], [1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2], [2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2], [2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1], [2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2], [2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2], [2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1], [2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1], [2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2], [1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2], [2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1], [2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2], [2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], [2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1], [2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2], [2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2], [2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1], [2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1], [2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2], [2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1], [2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2], [2, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2], [2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1], [2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1], [1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2], [2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1], [2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2], [2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1], [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2], [2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1], [2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2], [2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2], [2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2]], 'api_usage': [APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0)], 'api_usage_total': APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-50, num_output_tokens=-50, cost=0.0)}
INFO - tinypaper - Completed after 0:24:43
