INFO - tinypaper - Running command 'main'
INFO - tinypaper - Started run with ID "185"
/Users/karina/Documents/Coding/PyCharm/mme/src/model/model.py:19: UserWarning: Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  warnings.warn(
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:30<24:42, 30.26s/it]  4%|▍         | 2/50 [00:59<23:36, 29.52s/it]  6%|▌         | 3/50 [01:28<23:02, 29.42s/it]  8%|▊         | 4/50 [01:56<22:05, 28.81s/it] 10%|█         | 5/50 [02:23<21:08, 28.20s/it] 12%|█▏        | 6/50 [02:50<20:27, 27.90s/it] 14%|█▍        | 7/50 [03:19<20:09, 28.12s/it] 16%|█▌        | 8/50 [03:51<20:36, 29.44s/it] 18%|█▊        | 9/50 [04:20<19:56, 29.19s/it] 20%|██        | 10/50 [04:50<19:41, 29.54s/it] 22%|██▏       | 11/50 [05:21<19:23, 29.84s/it] 24%|██▍       | 12/50 [05:49<18:37, 29.41s/it] 26%|██▌       | 13/50 [06:22<18:50, 30.56s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.436(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 28%|██▊       | 14/50 [06:53<18:24, 30.67s/it] 30%|███       | 15/50 [07:23<17:40, 30.29s/it] 32%|███▏      | 16/50 [07:57<17:48, 31.43s/it] 34%|███▍      | 17/50 [08:26<16:53, 30.73s/it] 36%|███▌      | 18/50 [08:57<16:30, 30.94s/it] 38%|███▊      | 19/50 [09:27<15:46, 30.54s/it] 40%|████      | 20/50 [09:57<15:14, 30.50s/it] 42%|████▏     | 21/50 [10:25<14:20, 29.67s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.199(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 44%|████▍     | 22/50 [10:57<14:11, 30.42s/it] 46%|████▌     | 23/50 [11:25<13:16, 29.50s/it] 48%|████▊     | 24/50 [11:54<12:49, 29.59s/it] 50%|█████     | 25/50 [12:24<12:20, 29.62s/it] 52%|█████▏    | 26/50 [12:53<11:45, 29.39s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.418(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 54%|█████▍    | 27/50 [13:21<11:10, 29.15s/it] 56%|█████▌    | 28/50 [13:52<10:48, 29.47s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.500(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 58%|█████▊    | 29/50 [14:22<10:24, 29.75s/it] 60%|██████    | 30/50 [14:53<09:59, 30.00s/it] 62%|██████▏   | 31/50 [15:24<09:35, 30.29s/it] 64%|██████▍   | 32/50 [15:53<09:02, 30.11s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.494(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 66%|██████▌   | 33/50 [16:27<08:50, 31.19s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.623(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 68%|██████▊   | 34/50 [16:59<08:20, 31.29s/it] 70%|███████   | 35/50 [17:37<08:22, 33.51s/it] 72%|███████▏  | 36/50 [18:08<07:37, 32.66s/it] 74%|███████▍  | 37/50 [18:35<06:42, 30.93s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.209(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 76%|███████▌  | 38/50 [19:02<05:57, 29.79s/it] 78%|███████▊  | 39/50 [19:31<05:26, 29.64s/it]WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.799(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
WARNING - root - Finished call to 'model.google.GoogleModel._fetch' after 1.456(s), this was the 1st time calling it.
INFO - root - Retrying model.google.GoogleModel._fetch in 0.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.
 80%|████████  | 40/50 [20:00<04:55, 29.50s/it] 82%|████████▏ | 41/50 [20:28<04:20, 28.98s/it] 84%|████████▍ | 42/50 [20:58<03:53, 29.16s/it] 86%|████████▌ | 43/50 [21:25<03:20, 28.65s/it] 88%|████████▊ | 44/50 [21:57<02:58, 29.70s/it] 90%|█████████ | 45/50 [22:28<02:29, 29.97s/it] 92%|█████████▏| 46/50 [22:57<01:58, 29.74s/it] 94%|█████████▍| 47/50 [23:26<01:28, 29.35s/it] 96%|█████████▌| 48/50 [23:52<00:56, 28.35s/it] 98%|█████████▊| 49/50 [24:18<00:27, 27.87s/it]100%|██████████| 50/50 [24:46<00:00, 27.79s/it]100%|██████████| 50/50 [24:46<00:00, 29.73s/it]
INFO - tinypaper - Result: {'answers': [[1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2], [2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2], [2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1], [2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1], [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], [2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2], [1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2], [2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1], [2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1], [1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1], [2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1], [2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1], [1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1], [2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1], [2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2], [2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2], [2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2], [2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2], [1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2], [2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2], [1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1], [1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1], [1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2], [1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1], [2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], [1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2], [2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1], [2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2], [1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2], [1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 2], [1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2], [2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2], [1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1], [1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1], [2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2], [2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2], [2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1], [2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1], [1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2], [1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1], [2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2], [2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2], [2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1]], 'api_usage': [APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0), APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-1, num_output_tokens=-1, cost=0.0)], 'api_usage_total': APIUsage(name='gemini-1.0-pro-001', num_input_tokens=-50, num_output_tokens=-50, cost=0.0)}
INFO - tinypaper - Completed after 0:24:47
