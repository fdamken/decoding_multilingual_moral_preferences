INFO - tinypaper - Running command 'main'
INFO - tinypaper - Started run with ID "1"
  0%|          | 0/100 [00:00<?, ?it/s]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  1%|          | 1/100 [00:08<14:20,  8.70s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  2%|▏         | 2/100 [00:18<15:21,  9.40s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  3%|▎         | 3/100 [00:26<14:03,  8.70s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  4%|▍         | 4/100 [00:34<13:28,  8.43s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  5%|▌         | 5/100 [00:42<13:22,  8.44s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  6%|▌         | 6/100 [00:51<13:09,  8.40s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  7%|▋         | 7/100 [01:00<13:36,  8.78s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  8%|▊         | 8/100 [01:07<12:36,  8.22s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
  9%|▉         | 9/100 [01:16<12:40,  8.36s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 10%|█         | 10/100 [01:23<11:48,  7.87s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 11%|█         | 11/100 [01:30<11:32,  7.78s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 12%|█▏        | 12/100 [01:39<12:00,  8.19s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 13%|█▎        | 13/100 [01:47<11:26,  7.89s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 14%|█▍        | 14/100 [01:54<10:58,  7.66s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 15%|█▌        | 15/100 [02:02<10:57,  7.74s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 16%|█▌        | 16/100 [02:10<11:07,  7.95s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 17%|█▋        | 17/100 [02:18<11:06,  8.03s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.681000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.910000 seconds
 18%|█▊        | 18/100 [02:28<11:31,  8.44s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.418000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.383000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.526000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.803000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.749000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.608000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.894000 seconds
 19%|█▉        | 19/100 [02:41<13:12,  9.78s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.256000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.309000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.114000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.715000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.342000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.836000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.038000 seconds
 20%|██        | 20/100 [02:53<14:05, 10.57s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.428000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.583000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.845000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.999000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.876000 seconds
 21%|██        | 21/100 [03:04<14:01, 10.66s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.220000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.230000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.760000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.682000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.817000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.772000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.235000 seconds
 22%|██▏       | 22/100 [03:16<14:15, 10.97s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.352000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.430000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.580000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.328000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.691000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.214000 seconds
 23%|██▎       | 23/100 [03:27<14:18, 11.15s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.542000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.282000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.625000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.276000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.862000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.905000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.030000 seconds
 24%|██▍       | 24/100 [03:39<14:29, 11.44s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.189000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.191000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.438000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.512000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.632000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.587000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.369000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.754000 seconds
 25%|██▌       | 25/100 [03:50<14:09, 11.33s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.249000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.470000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.489000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.498000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.679000 seconds
 26%|██▌       | 26/100 [04:01<13:52, 11.24s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.174000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.088000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.704000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.767000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.320000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.896000 seconds
 27%|██▋       | 27/100 [04:13<13:48, 11.35s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.456000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.596000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.322000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.811000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.970000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.705000 seconds
 28%|██▊       | 28/100 [04:25<13:54, 11.59s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.195000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.326000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.239000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.667000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.305000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.583000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.512000 seconds
 29%|██▉       | 29/100 [04:36<13:22, 11.31s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.007000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.580000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.645000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.267000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.916000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.559000 seconds
 30%|███       | 30/100 [04:47<13:12, 11.32s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.426000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.062000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.673000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.538000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.845000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.083000 seconds
 31%|███       | 31/100 [04:59<13:07, 11.41s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.390000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.177000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.525000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.114000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.451000 seconds
 32%|███▏      | 32/100 [05:10<12:41, 11.20s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.428000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.222000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.665000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.628000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.464000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.581000 seconds
 33%|███▎      | 33/100 [05:21<12:29, 11.18s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.330000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.084000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.705000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.427000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.514000 seconds
 34%|███▍      | 34/100 [05:32<12:14, 11.13s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.471000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.494000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.408000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.552000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.569000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.493000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.917000 seconds
 35%|███▌      | 35/100 [05:44<12:21, 11.40s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.508000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.559000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.564000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.737000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.914000 seconds
 36%|███▌      | 36/100 [05:56<12:23, 11.62s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.106000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.546000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.642000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.013000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.996000 seconds
 37%|███▋      | 37/100 [06:07<12:06, 11.53s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.045000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.693000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.532000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.686000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.372000 seconds
 38%|███▊      | 38/100 [06:18<11:46, 11.39s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.459000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.077000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.449000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.761000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.920000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.569000 seconds
 39%|███▉      | 39/100 [06:31<11:58, 11.78s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.310000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.742000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.647000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.749000 seconds
 40%|████      | 40/100 [06:42<11:32, 11.53s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.103000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.472000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.275000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.476000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.858000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.741000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.064000 seconds
 41%|████      | 41/100 [06:52<11:04, 11.26s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.326000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.238000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.276000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.564000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.269000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.858000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.024000 seconds
 42%|████▏     | 42/100 [07:03<10:48, 11.18s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.440000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.051000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.665000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.346000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.805000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.037000 seconds
 43%|████▎     | 43/100 [07:15<10:41, 11.25s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.065000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.419000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.494000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.276000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.475000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.064000 seconds
 44%|████▍     | 44/100 [07:27<10:36, 11.37s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.533000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.705000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.760000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.886000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.846000 seconds
 45%|████▌     | 45/100 [07:38<10:27, 11.42s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.227000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.442000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.571000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.358000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.849000 seconds
 46%|████▌     | 46/100 [07:49<10:03, 11.18s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.220000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.599000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.748000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.679000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.796000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.119000 seconds
 47%|████▋     | 47/100 [08:01<10:03, 11.39s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.085000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.217000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.215000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.312000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.578000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.719000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.640000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.117000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.890000 seconds
 48%|████▊     | 48/100 [08:12<09:57, 11.49s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.264000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.426000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.550000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.689000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.068000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.196000 seconds
 49%|████▉     | 49/100 [08:25<10:00, 11.78s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.499000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.561000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.604000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.764000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.751000 seconds
 50%|█████     | 50/100 [08:35<09:30, 11.41s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.197000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.467000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.727000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.908000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.759000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.637000 seconds
 51%|█████     | 51/100 [08:48<09:32, 11.69s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.509000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.300000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.634000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.531000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.360000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.498000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.659000 seconds
 52%|█████▏    | 52/100 [08:59<09:20, 11.68s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.349000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.403000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.114000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.086000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.780000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.712000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.567000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.947000 seconds
 53%|█████▎    | 53/100 [09:12<09:17, 11.85s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.046000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.255000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.374000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.266000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.336000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.596000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.545000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.657000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.962000 seconds
 54%|█████▍    | 54/100 [09:23<08:55, 11.65s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.154000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.429000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.075000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.602000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.723000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.744000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.920000 seconds
 55%|█████▌    | 55/100 [09:34<08:35, 11.46s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.049000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.562000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.346000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.815000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.820000 seconds
 56%|█████▌    | 56/100 [09:45<08:25, 11.48s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.269000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.529000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.387000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.534000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.397000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.919000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.925000 seconds
 57%|█████▋    | 57/100 [09:57<08:16, 11.56s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.547000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.596000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.627000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.720000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.945000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.503000 seconds
 58%|█████▊    | 58/100 [10:08<07:55, 11.33s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.439000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.426000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.483000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.666000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.644000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.669000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.127000 seconds
 59%|█████▉    | 59/100 [10:18<07:35, 11.12s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.033000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.524000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.691000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.580000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.986000 seconds
 60%|██████    | 60/100 [10:30<07:25, 11.14s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.229000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.412000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.520000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.509000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.746000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.781000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.953000 seconds
 61%|██████    | 61/100 [10:41<07:13, 11.13s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.362000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.410000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.354000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.125000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.493000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.313000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.771000 seconds
 62%|██████▏   | 62/100 [10:52<06:59, 11.03s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.029000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.318000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.404000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.220000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.334000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.975000 seconds
 63%|██████▎   | 63/100 [11:02<06:43, 10.91s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.326000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.467000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.470000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.550000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.419000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.881000 seconds
 64%|██████▍   | 64/100 [11:13<06:35, 10.99s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.272000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.129000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.713000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.816000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.936000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.516000 seconds
 65%|██████▌   | 65/100 [11:24<06:20, 10.86s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.138000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.587000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.271000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.771000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.817000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.013000 seconds
 66%|██████▌   | 66/100 [11:35<06:09, 10.86s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.412000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.430000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.432000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.703000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.315000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.646000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.774000 seconds
 67%|██████▋   | 67/100 [11:46<05:59, 10.90s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.091000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.364000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.395000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.373000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.679000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.765000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.927000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.868000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.164000 seconds
 68%|██████▊   | 68/100 [11:59<06:06, 11.46s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.219000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.500000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.454000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.740000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.830000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.941000 seconds
 69%|██████▉   | 69/100 [12:09<05:49, 11.26s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.349000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.266000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.398000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.071000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.552000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.748000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.534000 seconds
 70%|███████   | 70/100 [12:21<05:39, 11.31s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.385000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.466000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.165000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.628000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.747000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.907000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.699000 seconds
 71%|███████   | 71/100 [12:32<05:28, 11.34s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.250000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.187000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.241000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.521000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.565000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.652000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.837000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.789000 seconds
 72%|███████▏  | 72/100 [12:43<05:12, 11.17s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.143000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.576000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.651000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.765000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.877000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.023000 seconds
 73%|███████▎  | 73/100 [12:55<05:07, 11.40s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.352000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.144000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.740000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.557000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.734000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.085000 seconds
 74%|███████▍  | 74/100 [13:06<04:53, 11.28s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.124000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.531000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.444000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.665000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.645000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.919000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.041000 seconds
 75%|███████▌  | 75/100 [13:18<04:45, 11.42s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.140000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.431000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.513000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.155000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.305000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.783000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.938000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.857000 seconds
 76%|███████▌  | 76/100 [13:30<04:37, 11.58s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.175000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.293000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.335000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.276000 seconds
 77%|███████▋  | 77/100 [14:16<08:24, 21.93s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 78%|███████▊  | 78/100 [14:22<06:21, 17.34s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 79%|███████▉  | 79/100 [14:30<05:00, 14.32s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 80%|████████  | 80/100 [14:36<03:57, 11.90s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 81%|████████  | 81/100 [14:41<03:10, 10.04s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 82%|████████▏ | 82/100 [14:48<02:39,  8.83s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
 83%|████████▎ | 83/100 [14:54<02:16,  8.05s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.089000 seconds
 84%|████████▍ | 84/100 [15:00<02:00,  7.56s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.539000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.176000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.656000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.625000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.898000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.015000 seconds
 85%|████████▌ | 85/100 [15:11<02:10,  8.69s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.037000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.178000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.291000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.385000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.580000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.539000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.541000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.924000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.540000 seconds
 86%|████████▌ | 86/100 [15:23<02:13,  9.55s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.651000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.372000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.469000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.377000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.897000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.871000 seconds
 87%|████████▋ | 87/100 [15:34<02:09,  9.96s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.270000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.737000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.910000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.789000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.853000 seconds
 88%|████████▊ | 88/100 [15:46<02:08, 10.70s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.681000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.517000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.599000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.687000 seconds
 89%|████████▉ | 89/100 [15:57<01:57, 10.66s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.093000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.306000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.599000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.395000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.384000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.955000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.806000 seconds
 90%|█████████ | 90/100 [16:08<01:48, 10.87s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.112000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.325000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.491000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.529000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.069000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.771000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.054000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.861000 seconds
 91%|█████████ | 91/100 [16:20<01:39, 11.01s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.116000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.197000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.264000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.096000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.666000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.381000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.474000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.926000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 1.087000 seconds
 92%|█████████▏| 92/100 [16:32<01:31, 11.49s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.461000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.296000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.216000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.645000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.788000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.503000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.999000 seconds
 93%|█████████▎| 93/100 [16:44<01:21, 11.61s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.246000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.209000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.317000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.429000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.527000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.416000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.789000 seconds
 94%|█████████▍| 94/100 [16:55<01:07, 11.31s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.194000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.377000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.529000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.500000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.766000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.693000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.799000 seconds
 95%|█████████▌| 95/100 [17:06<00:56, 11.30s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.460000 seconds
 96%|█████████▌| 96/100 [17:21<00:49, 12.36s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.862000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.826000 seconds
 97%|█████████▋| 97/100 [17:29<00:33, 11.07s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.443000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.299000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.600000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.664000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.825000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.450000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.596000 seconds
 98%|█████████▊| 98/100 [17:40<00:22, 11.15s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.156000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.222000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.392000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.210000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.263000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.470000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.748000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.919000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.566000 seconds
 99%|█████████▉| 99/100 [17:52<00:11, 11.24s/it]WARNING - __init__ - Running model NOT in dry mode! This will consume API tokens and may cost money. MAKE SURE TO RUN IN DRY MODE FIRST TO GET AN ESTIMATE!
INFO - openai._base_client - Retrying request to /chat/completions in 0.451000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.547000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.183000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.524000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.623000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.559000 seconds
INFO - openai._base_client - Retrying request to /chat/completions in 0.843000 seconds
100%|██████████| 100/100 [18:03<00:00, 11.31s/it]100%|██████████| 100/100 [18:03<00:00, 10.84s/it]
INFO - tinypaper - Result: {'answers': [['1', '2', '2', '1', '2', '2', '1', '1', '1', '2', '2', '1', '1'], ['1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1'], ['1', '2', '1', '1', '2', '2', '1', '1', '2', '2', '1', '2', '1'], ['2', '1', '1', '2', '1', '2', '1', '1', '2', '1', '2', '1', '2'], ['1', '1', '2', '1', '2', '2', '1', '2', '1', '2', '2', '2', '1'], ['1', '2', '1', '2', '2', '1', '1', '1', '1', '1', '2', '1', '1'], ['1', '2', '1', '2', '2', '1', '1', '2', '1', '2', '2', '2', '1'], ['2', '1', '2', '2', '2', '2', '1', '1', '1', '2', '1', '2', '1'], ['2', '1', '2', '1', '1', '2', '1', '2', '1', '2', '1', '2', '1'], ['1', '1', '2', '1', '2', '2', '1', '1', '1', '2', '1', '1', '1'], ['2', '1', '2', '2', '1', '1', '1', '2', '1', '1', '1', '1', '2'], ['1', '1', '1', '2', '2', '1', '2', '2', '2', '1', '1', '2', '2'], ['1', '2', '1', '2', '1', '2', '1', '1', '2', '1', '1', '2', '1'], ['1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1'], ['2', '2', '1', '2', '1', '2', '1', '1', '1', '2', '1', '2', '1'], ['2', '1', '2', '2', '2', '2', '2', '1', '2', '1', '1', '2', '2'], ['2', '1', '2', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1'], ['2', '2', '1', '2', '1', '1', '2', '1', '1', '2', '1', '1', '1'], ['1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1'], ['1', '2', '1', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1'], ['1', '2', '2', '2', '2', '1', '2', '1', '2', '2', '1', '2', '1'], ['2', '1', '2', '2', '1', '1', '2', '1', '1', '2', '1', '1', '2'], ['1', '1', '1', '2', '1', '1', '1', '1', '2', '1', '2', '1', '1'], ['1', '1', '2', '1', '1', '1', '1', '1', '2', '2', '2', '1', '2'], ['1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '2'], ['1', '2', '1', '1', '2', '1', '2', '1', '1', '2', '2', '2', '1'], ['2', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1'], ['2', '1', '1', '2', '2', '2', '2', '1', '2', '1', '1', '2', '1'], ['2', '2', '2', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1'], ['1', '2', '1', '2', '1', '1', '2', '2', '1', '1', '1', '1', '2'], ['1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '2', '1', '2'], ['1', '1', '2', '1', '2', '1', '2', '2', '2', '1', '2', '1', '1'], ['2', '1', '2', '2', '1', '1', '1', '2', '1', '2', '1', '2', '1'], ['2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '2'], ['1', '2', '1', '2', '2', '1', '1', '2', '2', '1', '2', '1', '2'], ['1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1'], ['1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '1'], ['2', '2', '1', '1', '2', '2', '2', '1', '1', '1', '2', '1', '1'], ['1', '2', '1', '1', '1', '2', '1', '1', '2', '2', '1', '1', '2'], ['1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1'], ['2', '1', '1', '2', '1', '1', '2', '2', '2', '1', '1', '1', '1'], ['2', '1', '2', '1', '1', '2', '1', '2', '1', '2', '1', '1', '2'], ['1', '2', '2', '1', '1', '2', '1', '1', '2', '2', '2', '1', '1'], ['2', '2', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '2'], ['2', '2', '2', '2', '2', '2', '1', '2', '2', '1', '2', '1', '1'], ['2', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1'], ['2', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '2'], ['1', '1', '2', '2', '2', '1', '1', '1', '1', '1', '2', '1', '2'], ['1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1'], ['1', '1', '2', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2'], ['2', '1', '2', '2', '1', '2', '1', '2', '1', '1', '2', '1', '1'], ['2', '2', '1', '1', '2', '1', '1', '2', '2', '1', '1', '1', '2'], ['1', '2', '2', '1', '1', '2', '1', '1', '2', '2', '1', '1', '1'], ['2', '2', '2', '1', '1', '2', '2', '1', '2', '2', '2', '1', '1'], ['2', '2', '1', '1', '1', '2', '2', '2', '1', '2', '1', '1', '1'], ['1', '1', '2', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1'], ['1', '2', '2', '1', '1', '2', '1', '2', '1', '1', '2', '1', '1'], ['1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '2'], ['1', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1'], ['2', '1', '1', '2', '1', '1', '1', '1', '1', '2', '2', '1', '1'], ['2', '1', '2', '1', '1', '1', '1', '2', '1', '2', '2', '2', '2'], ['1', '1', '2', '1', '2', '1', '2', '1', '1', '2', '1', '2', '2'], ['2', '2', '1', '1', '1', '1', '2', '1', '1', '2', '2', '2', '1'], ['2', '1', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '2'], ['2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1'], ['2', '1', '2', '1', '1', '2', '1', '1', '2', '1', '1', '1', '2'], ['1', '1', '2', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1'], ['1', '1', '1', '2', '2', '2', '1', '2', '1', '1', '2', '2', '1'], ['1', '2', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1'], ['2', '1', '2', '1', '1', '1', '2', '1', '2', '1', '1', '1', '2'], ['1', '1', '1', '2', '2', '2', '1', '1', '2', '1', '1', '2', '2'], ['1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1'], ['2', '1', '1', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1'], ['1', '2', '1', '1', '1', '2', '2', '1', '1', '2', '1', '1', '1'], ['2', '1', '1', '1', '2', '1', '2', '1', '2', '1', '1', '1', '1'], ['2', '2', '1', '1', '2', '2', '1', '2', '2', '1', '1', '2', '2'], ['1', '2', '2', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1'], ['1', '1', '1', '1', '1', '2', '1', '2', '2', '1', '1', '2', '2'], ['2', '2', '1', '2', '1', '2', '2', '2', '1', '2', '1', '1', '1'], ['2', '2', '1', '2', '1', '2', '2', '2', '1', '1', '1', '1', '1'], ['1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1'], ['1', '1', '1', '2', '2', '1', '2', '1', '1', '2', '1', '1', '1'], ['1', '1', '2', '1', '2', '2', '1', '1', '1', '1', '2', '1', '1'], ['1', '2', '2', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1'], ['2', '1', '1', '2', '1', '1', '2', '1', '1', '2', '1', '2', '2'], ['1', '2', '1', '2', '1', '2', '1', '1', '2', '2', '1', '1', '1'], ['2', '1', '2', '1', '2', '2', '2', '2', '1', '1', '2', '2', '1'], ['1', '1', '1', '1', '2', '1', '2', '1', '1', '2', '2', '1', '1'], ['2', '2', '2', '2', '2', '1', '2', '2', '2', '1', '2', '1', '2'], ['1', '1', '1', '1', '2', '1', '1', '2', '2', '1', '1', '1', '1'], ['1', '2', '1', '1', '2', '2', '2', '1', '2', '1', '2', '1', '2'], ['1', '1', '1', '2', '1', '2', '1', '2', '1', '2', '2', '1', '1'], ['1', '1', '2', '2', '1', '1', '1', '2', '2', '1', '1', '2', '1'], ['1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '2', '1'], ['2', '1', '2', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1'], ['1', '1', '2', '1', '2', '1', '2', '2', '1', '1', '2', '2', '1'], ['1', '1', '1', '2', '2', '1', '2', '1', '2', '1', '1', '1', '2'], ['1', '1', '1', '1', '1', '2', '2', '2', '1', '2', '1', '2', '1'], ['2', '2', '1', '2', '1', '2', '2', '1', '2', '2', '1', '1', '2'], ['2', '1', '1', '1', '2', '1', '1', '2', '2', '1', '1', '1', '1']], 'api_usage': [APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11187, num_output_tokens=13, cost=0.005613), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11080, num_output_tokens=13, cost=0.0055595), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10527, num_output_tokens=13, cost=0.005283), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10964, num_output_tokens=13, cost=0.0055015), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11822, num_output_tokens=13, cost=0.0059305), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11722, num_output_tokens=13, cost=0.0058805), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10808, num_output_tokens=13, cost=0.0054235), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11416, num_output_tokens=13, cost=0.0057275), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11976, num_output_tokens=13, cost=0.0060075), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11798, num_output_tokens=13, cost=0.0059185), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11833, num_output_tokens=13, cost=0.005936), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11273, num_output_tokens=13, cost=0.005656), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11683, num_output_tokens=13, cost=0.005861), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11981, num_output_tokens=13, cost=0.00601), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11272, num_output_tokens=13, cost=0.0056555), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=12003, num_output_tokens=13, cost=0.006021), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10992, num_output_tokens=13, cost=0.0055155), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=12054, num_output_tokens=13, cost=0.0060465), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=12814, num_output_tokens=13, cost=0.0064265), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11666, num_output_tokens=13, cost=0.0058525), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11709, num_output_tokens=13, cost=0.005874), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11687, num_output_tokens=13, cost=0.005863), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11482, num_output_tokens=13, cost=0.0057605), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11723, num_output_tokens=13, cost=0.005881), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11333, num_output_tokens=13, cost=0.005686), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11208, num_output_tokens=13, cost=0.0056235), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11468, num_output_tokens=13, cost=0.0057535), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11936, num_output_tokens=13, cost=0.0059875), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10935, num_output_tokens=13, cost=0.005487), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11213, num_output_tokens=13, cost=0.005626), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10795, num_output_tokens=13, cost=0.005417), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11123, num_output_tokens=13, cost=0.005581), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11097, num_output_tokens=13, cost=0.005568), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11347, num_output_tokens=13, cost=0.005693), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11786, num_output_tokens=13, cost=0.0059125), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=12099, num_output_tokens=13, cost=0.006069), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11600, num_output_tokens=13, cost=0.0058195), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11175, num_output_tokens=13, cost=0.005607), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11954, num_output_tokens=13, cost=0.0059965), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10771, num_output_tokens=13, cost=0.005405), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11618, num_output_tokens=13, cost=0.0058285), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10758, num_output_tokens=13, cost=0.0053985), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11120, num_output_tokens=13, cost=0.0055795), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=12012, num_output_tokens=13, cost=0.0060255), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11367, num_output_tokens=13, cost=0.005703), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10774, num_output_tokens=13, cost=0.0054065), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11940, num_output_tokens=13, cost=0.0059895), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11682, num_output_tokens=13, cost=0.0058605), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11957, num_output_tokens=13, cost=0.005998), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10939, num_output_tokens=13, cost=0.005489), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11866, num_output_tokens=13, cost=0.0059525), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=12175, num_output_tokens=13, cost=0.006107), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=12229, num_output_tokens=13, cost=0.006134), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11064, num_output_tokens=13, cost=0.0055515), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10722, num_output_tokens=13, cost=0.0053805), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11488, num_output_tokens=13, cost=0.0057635), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11805, num_output_tokens=13, cost=0.005922), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11087, num_output_tokens=13, cost=0.005563), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10665, num_output_tokens=13, cost=0.005352), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11208, num_output_tokens=13, cost=0.0056235), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11124, num_output_tokens=13, cost=0.0055815), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10517, num_output_tokens=13, cost=0.005278), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10389, num_output_tokens=13, cost=0.005214), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10799, num_output_tokens=13, cost=0.005419), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11129, num_output_tokens=13, cost=0.005584), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10806, num_output_tokens=13, cost=0.0054225), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11022, num_output_tokens=13, cost=0.0055305), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=12514, num_output_tokens=13, cost=0.0062765), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11273, num_output_tokens=13, cost=0.005656), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11329, num_output_tokens=13, cost=0.005684), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11428, num_output_tokens=13, cost=0.0057335), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10750, num_output_tokens=13, cost=0.0053945), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11506, num_output_tokens=13, cost=0.0057725), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11341, num_output_tokens=13, cost=0.00569), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11829, num_output_tokens=13, cost=0.005934), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11964, num_output_tokens=13, cost=0.0060015), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10563, num_output_tokens=13, cost=0.005301), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11583, num_output_tokens=13, cost=0.005811), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11949, num_output_tokens=13, cost=0.005994), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10889, num_output_tokens=13, cost=0.005464), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11481, num_output_tokens=13, cost=0.00576), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11368, num_output_tokens=13, cost=0.0057035), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11515, num_output_tokens=13, cost=0.005777), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11094, num_output_tokens=13, cost=0.0055665), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11352, num_output_tokens=13, cost=0.0056955), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11095, num_output_tokens=13, cost=0.005567), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11334, num_output_tokens=13, cost=0.0056865), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11927, num_output_tokens=13, cost=0.005983), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10557, num_output_tokens=13, cost=0.005298), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11686, num_output_tokens=13, cost=0.0058625), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11435, num_output_tokens=13, cost=0.005737), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=12402, num_output_tokens=13, cost=0.0062205), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11752, num_output_tokens=13, cost=0.0058955), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=10856, num_output_tokens=13, cost=0.0054475), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11186, num_output_tokens=13, cost=0.0056125), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11629, num_output_tokens=13, cost=0.005834), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11338, num_output_tokens=13, cost=0.0056885), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11390, num_output_tokens=13, cost=0.0057145), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11419, num_output_tokens=13, cost=0.005729), APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=11496, num_output_tokens=13, cost=0.0057675)], 'api_usage_total': APIUsage(name='gpt-3.5-turbo-0125', num_input_tokens=1140804, num_output_tokens=1300, cost=0.5723519999999999)}
INFO - tinypaper - Completed after 0:18:04
